# -*- coding: utf-8 -*-
"""RAG_based_chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eEa3qXx4BB6d4j3VXzZ4zWI_qYnYCI2u

Installing Dependencies
"""

!pip install sentence-transformers scikit-learn requests
pip install gradio



#uploading files containing documnet and api key
from google.colab import files

uploaded = files.upload()

# Reading API key
with open("/content/groq_api_key.txt", "r") as f:
    for line in f:
        if line.startswith("GROQ_KEY"):
            GROQ_API_KEY = line.split("=",1)[1].strip()

# Reading document
with open("/content/document.txt", "r", encoding="utf-8") as f:
    text = f.read()

"""Loading embedding model and spliting text into chunks"""

from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# Loading embeddings model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Spliting text into chunks
def split_text(text, chunk_size=500):
    words = text.split()
    return [" ".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]

chunks = split_text(text)

# create embeddings of chunks
chunk_embeddings = model.encode(chunks)

"""similarity check between question and text"""

def retrieve_context(query, top_k=3):
    # turning the question(query) into vector
    query_emb = model.encode([query])
    similarities = cosine_similarity(query_emb, chunk_embeddings)[0]
    top_indices = np.argsort(similarities)[::-1][:top_k] # sorting score in descending order
    return [chunks[i] for i in top_indices]

import requests

def ask_groq(query):
    context = "\n".join(retrieve_context(query))

    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {GROQ_API_KEY}", "Content-Type": "application/json"}
    payload = {
        "model": "llama-3.3-70b-versatile",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": f"Question: {query}\n\nRelevant context:\n{context}"}
        ]
    }

    response = requests.post(url, headers=headers, json=payload)
    response.raise_for_status()
    return response.json()["choices"][0]["message"]["content"]

import gradio as gr

def chat_fn(message, history):
    try:
        return ask_groq(message)
    except Exception as e:
        return f"‚ùå Error: {e}"

demo = gr.ChatInterface(
    fn=chat_fn,
    title="üìö RAG Chatbot (Groq)",
    description="Ask questions about the uploaded document."
)

demo.launch(share=True)



